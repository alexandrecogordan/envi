{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 OPR/94.0.0.0'})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_attribute(attribute):\n",
    "    if attribute:\n",
    "        return attribute.text.strip()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(element):\n",
    "    list = []\n",
    "\n",
    "    for element in element:\n",
    "        if element:\n",
    "            return list.append(element.text.strip().replace('\\n', ' change here'))\n",
    "        return list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product(url):\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    # products = soup.find('div', class_='list__container')\n",
    "\n",
    "    attributes = {'Name':[], 'Image Link':[], 'Origin':[], 'Price':[], 'Unit Price':[], 'Bio':[]}\n",
    "    \n",
    "    attributes['Name'] = convert_to_list(soup.find_all('p', class_='product-thumbnail__description'))\n",
    "    attributes['Price'] = convert_to_list(soup.find_all('div', class_='product-price bolder text-dark-color'))    \n",
    "    attributes['Image Link'] = convert_to_list(soup.find_all('img', class_='product-thumbnail__image'))\n",
    "    attributes['Origin'] = convert_to_list(soup.find_all('span', class_='rectangular-badge__RectangularBadge-sc-1k9mcpf-0 base__CountryOfOrigin-sc-1mnb0pd-46 jPSXAR gYAJJo'))\n",
    "    attributes['Unit Price'] = convert_to_list(soup.find_all('span', class_='text__Text-sc-6l1yjp-0 standard-promotion__PromotionIntentText-sc-1vpsrpe-2 fop__PricePerText-sc-sgv9y1-5 dLNLFE fAoahS eNYENy'))\n",
    "    \n",
    "\n",
    "    #for product in products:\n",
    "        #product.find('p', class_='product-thumbnail__description', itemprop='name description')\n",
    "\n",
    "    # for product in products:\n",
    "    #     name = product.find('p', class_='product-thumbnail__description')\n",
    "    #     origin = product.find('span', class_='rectangular-badge__RectangularBadge-sc-1k9mcpf-0 base__CountryOfOrigin-sc-1mnb0pd-46 jPSXAR gYAJJo')\n",
    "    #     price = product.find('div', class_='product-price bolder text-dark-color')\n",
    "    #     #unit_price = product.find('span', class_='text__Text-sc-6l1yjp-0 standard-promotion__PromotionIntentText-sc-1vpsrpe-2 fop__PricePerText-sc-sgv9y1-5 dLNLFE fAoahS eNYENy')\n",
    "\n",
    "    #     attributes['Name'].append(add_attribute(name))\n",
    "    #     attributes['Origin'].append(add_attribute(origin))\n",
    "    #     attributes['Price'].append(add_attribute(price))\n",
    "    #     attributes['Unit Price'].append(None)\n",
    "    #     attributes['Image Link'].append(None)\n",
    "\n",
    "    for name in attributes['Name']:\n",
    "        if name:\n",
    "            if 'bio' in name.lower():\n",
    "                attributes['Bio'].append(True)\n",
    "            else:\n",
    "                attributes['Bio'].append(False)\n",
    "        else:\n",
    "            attributes['Bio'].append(None)\n",
    "\n",
    "    for items in attributes:\n",
    "        print(len(attributes[items]))\n",
    "\n",
    "    attribute_df = pd.DataFrame(attributes) \n",
    "    attribute_df.dropna(how = 'all', inplace=True)\n",
    "\n",
    "    return attribute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_page(url):\n",
    "    soup = scrape(url)\n",
    "\n",
    "    pages = soup.find('div', class_='pagination-links__container').find_all('a', class_='pagination-item')\n",
    "    max_page = pages[-1].text.strip()\n",
    "\n",
    "    return int(max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.auchan.fr/fruits-legumes/fruits/ca-n0301?page=1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m page_counter \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m get_max_page(url):\n\u001b[0;32m----> 5\u001b[0m     retail_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_counter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     page_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[176], line 43\u001b[0m, in \u001b[0;36mget_product\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     25\u001b[0m attributes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnit Price\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m convert_to_list(soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext__Text-sc-6l1yjp-0 standard-promotion__PromotionIntentText-sc-1vpsrpe-2 fop__PricePerText-sc-sgv9y1-5 dLNLFE fAoahS eNYENy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#for product in products:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#product.find('p', class_='product-thumbnail__description', itemprop='name description')\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#     attributes['Unit Price'].append(None)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#     attributes['Image Link'].append(None)\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attributes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbio\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name\u001b[38;5;241m.\u001b[39mlower():\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "page_counter = 1\n",
    "url = 'https://www.auchan.fr/fruits-legumes/fruits/ca-n0301?page=1'\n",
    "\n",
    "while page_counter <= get_max_page(url):\n",
    "    retail_df = get_product(url[:-1] + str(page_counter))\n",
    "    page_counter += 1\n",
    "    break\n",
    "\n",
    "retail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retail_df.to_csv('auchan.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
